{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cb3ee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T19:28:20.955190Z",
     "start_time": "2021-04-22T19:28:20.951359Z"
    }
   },
   "source": [
    "# launch Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416ddbe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T12:17:12.035774Z",
     "start_time": "2021-05-21T12:17:09.169269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/navsim/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray import tune\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b767390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T12:17:12.088083Z",
     "start_time": "2021-05-21T12:17:12.049512Z"
    }
   },
   "outputs": [],
   "source": [
    "import navsim\n",
    "navsim.NavSimGymEnv.register_with_ray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0eceae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T12:17:17.888402Z",
     "start_time": "2021-05-21T12:17:15.741506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 08:17:16,225\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.14',\n",
       " 'raylet_ip_address': '192.168.1.14',\n",
       " 'redis_address': '192.168.1.14:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-05-21_08-17-15_746192_53156/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-05-21_08-17-15_746192_53156/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-05-21_08-17-15_746192_53156',\n",
       " 'metrics_export_port': 61778,\n",
       " 'node_id': '2d2cec3141eff8a33539cfa1bc65d08d7bd06be2ea00f4176807d1d5'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9425d3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T12:17:29.284978Z",
     "start_time": "2021-05-21T12:17:29.279015Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"log_level\"] = \"WARN\"\n",
    "config[\"framework\"] = \"torch\"\n",
    "config[\"env\"]=\"Taxi-v3\"\n",
    "config[\"env\"]=\"navsim\"\n",
    "config[\"num_workers\"]=1\n",
    "config[\"env_config\"][\"env_path\"]=\"/data/work/unity-envs/Build2.7.0/Berlin_Walk_V2.x86_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e398fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T12:17:32.029764Z",
     "start_time": "2021-05-21T12:17:32.014856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_fake_gpus: false\n",
      "_use_trajectory_view_api: true\n",
      "batch_mode: truncate_episodes\n",
      "callbacks: <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>\n",
      "clip_actions: true\n",
      "clip_param: 0.3\n",
      "collect_metrics_timeout: 180\n",
      "compress_observations: false\n",
      "create_env_on_driver: false\n",
      "custom_resources_per_worker: {}\n",
      "eager_tracing: false\n",
      "entropy_coeff: 0.0\n",
      "env: navsim\n",
      "env_config:\n",
      "  env_path: /data/work/unity-envs/Build2.6.4/Berlin_Walk_V2.x86_64\n",
      "evaluation_config: {}\n",
      "evaluation_num_episodes: 10\n",
      "evaluation_num_workers: 0\n",
      "exploration_config:\n",
      "  type: StochasticSampling\n",
      "explore: true\n",
      "extra_python_environs_for_driver: {}\n",
      "extra_python_environs_for_worker: {}\n",
      "fake_sampler: false\n",
      "framework: torch\n",
      "gamma: 0.99\n",
      "ignore_worker_failures: false\n",
      "in_evaluation: false\n",
      "input: sampler\n",
      "input_evaluation:\n",
      "- is\n",
      "- wis\n",
      "kl_coeff: 0.2\n",
      "kl_target: 0.01\n",
      "lambda: 1.0\n",
      "local_tf_session_args:\n",
      "  inter_op_parallelism_threads: 8\n",
      "  intra_op_parallelism_threads: 8\n",
      "log_level: WARN\n",
      "log_sys_usage: true\n",
      "lr: 5.0e-05\n",
      "memory: 0\n",
      "memory_per_worker: 0\n",
      "metrics_smoothing_episodes: 100\n",
      "min_iter_time_s: 0\n",
      "model:\n",
      "  _time_major: false\n",
      "  attention_dim: 64\n",
      "  attention_head_dim: 32\n",
      "  attention_init_gru_gate_bias: 2.0\n",
      "  attention_memory_inference: 50\n",
      "  attention_memory_training: 50\n",
      "  attention_num_heads: 1\n",
      "  attention_num_transformer_units: 1\n",
      "  attention_position_wise_mlp_dim: 32\n",
      "  conv_activation: relu\n",
      "  conv_filters: null\n",
      "  custom_action_dist: null\n",
      "  custom_model: null\n",
      "  custom_model_config: {}\n",
      "  custom_preprocessor: null\n",
      "  dim: 84\n",
      "  fcnet_activation: tanh\n",
      "  fcnet_hiddens:\n",
      "  - 256\n",
      "  - 256\n",
      "  framestack: true\n",
      "  free_log_std: false\n",
      "  grayscale: false\n",
      "  lstm_cell_size: 256\n",
      "  lstm_use_prev_action: false\n",
      "  lstm_use_prev_action_reward: -1\n",
      "  lstm_use_prev_reward: false\n",
      "  max_seq_len: 20\n",
      "  no_final_linear: false\n",
      "  num_framestacks: auto\n",
      "  use_attention: false\n",
      "  use_lstm: false\n",
      "  vf_share_layers: false\n",
      "  zero_mean: true\n",
      "monitor: false\n",
      "multiagent:\n",
      "  count_steps_by: env_steps\n",
      "  observation_fn: null\n",
      "  policies: {}\n",
      "  policies_to_train: null\n",
      "  policy_mapping_fn: null\n",
      "  replay_mode: independent\n",
      "no_done_at_end: false\n",
      "normalize_actions: false\n",
      "num_cpus_for_driver: 1\n",
      "num_cpus_per_worker: 1\n",
      "num_envs_per_worker: 1\n",
      "num_gpus: 0\n",
      "num_gpus_per_worker: 0\n",
      "num_sgd_iter: 30\n",
      "num_workers: 1\n",
      "object_store_memory: 0\n",
      "object_store_memory_per_worker: 0\n",
      "observation_filter: NoFilter\n",
      "optimizer: {}\n",
      "output_compress_columns:\n",
      "- obs\n",
      "- new_obs\n",
      "output_max_file_size: 67108864\n",
      "postprocess_inputs: false\n",
      "preprocessor_pref: deepmind\n",
      "remote_env_batch_wait_ms: 0\n",
      "remote_worker_envs: false\n",
      "replay_sequence_length: 1\n",
      "rollout_fragment_length: 200\n",
      "sample_async: false\n",
      "sample_collector: <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>\n",
      "sgd_minibatch_size: 128\n",
      "shuffle_buffer_size: 0\n",
      "shuffle_sequences: true\n",
      "simple_optimizer: false\n",
      "soft_horizon: false\n",
      "synchronize_filters: true\n",
      "tf_session_args:\n",
      "  allow_soft_placement: true\n",
      "  device_count:\n",
      "    CPU: 1\n",
      "  gpu_options:\n",
      "    allow_growth: true\n",
      "  inter_op_parallelism_threads: 2\n",
      "  intra_op_parallelism_threads: 2\n",
      "  log_device_placement: false\n",
      "timesteps_per_iteration: 0\n",
      "train_batch_size: 4000\n",
      "use_critic: true\n",
      "use_gae: true\n",
      "vf_clip_param: 10.0\n",
      "vf_loss_coeff: 1.0\n",
      "vf_share_layers: -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pretty_print(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7176dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T12:52:33.506951Z",
     "start_time": "2021-05-21T12:18:12.002395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/30.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/16 CPUs, 0/1 GPUs, 0.0/15.82 GiB heap, 0.0/5.42 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/afandang/exp/nb/PPO_2021-05-21_08-18-12<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_navsim_9c696_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=53290)\u001b[0m WARNING:tensorflow:From /opt/conda/envs/navsim/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=53290)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=53290)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=53290)\u001b[0m 2021-05-21 08:18:14,444\tINFO trainer.py:641 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m WARNING:tensorflow:From /opt/conda/envs/navsim/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m Found path: /data/work/unity-envs/Build2.6.4/Berlin_Walk_V2.x86_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m 2021-05-21 08:18:19 INFO [environment.py:110] Connected to Unity environment with package version 1.7.2-preview and communication version 1.3.0\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m 2021-05-21 08:18:21 INFO [environment.py:271] Connected new brain:\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m VectorVisualNavigator?team=0\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m /opt/conda/envs/navsim/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m 2021-05-21 08:18:33,395\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=53290)\u001b[0m 2021-05-21 08:18:34,048\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=53290)\u001b[0m 2021-05-21 08:18:34,633\tINFO trainable.py:100 -- Trainable.setup took 20.224 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m 2021-05-21 08:18:40,242\tWARNING deprecation.py:33 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_navsim_9c696_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-05-21_08-35-38\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -7.210000229097204\n",
      "  episode_reward_mean: -8.815000258084728\n",
      "  episode_reward_min: -18.210000401530124\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 40\n",
      "  experiment_id: d473c3ca2c0141a5a2d91ee359fd51b8\n",
      "  hostname: thunderball\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 4.263133555650711\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01408003966207616\n",
      "        policy_loss: -0.033419892366509885\n",
      "        total_loss: 0.8618390168994665\n",
      "        vf_explained_var: 0.7733805179595947\n",
      "        vf_loss: 0.8924429006874561\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.14\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.474135446685878\n",
      "    gpu_util_percent0: 0.38427953890489913\n",
      "    ram_util_percent: 56.84625360230548\n",
      "    vram_util_percent0: 0.599579888863959\n",
      "  pid: 53290\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11444097755849733\n",
      "    mean_env_wait_ms: 76.70104405308508\n",
      "    mean_inference_ms: 6.937402392947296\n",
      "    mean_raw_obs_processing_ms: 60.24793260427035\n",
      "  time_since_restore: 1023.7109594345093\n",
      "  time_this_iter_s: 1023.7109594345093\n",
      "  time_total_s: 1023.7109594345093\n",
      "  timers:\n",
      "    learn_throughput: 8.954\n",
      "    learn_time_ms: 446712.237\n",
      "    sample_throughput: 6.933\n",
      "    sample_time_ms: 576951.26\n",
      "    update_time_ms: 13.154\n",
      "  timestamp: 1621600538\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 9c696_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/30.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/16 CPUs, 0/1 GPUs, 0.0/15.82 GiB heap, 0.0/5.42 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/afandang/exp/nb/PPO_2021-05-21_08-18-12<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_navsim_9c696_00000</td><td>RUNNING </td><td>192.168.1.14:53290</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1023.71</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">  -8.815</td><td style=\"text-align: right;\">               -7.21</td><td style=\"text-align: right;\">              -18.21</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_navsim_9c696_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-05-21_08-52-27\n",
      "  done: true\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -6.41000020361389\n",
      "  episode_reward_mean: -8.450000252339123\n",
      "  episode_reward_min: -18.210000401530124\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 80\n",
      "  experiment_id: d473c3ca2c0141a5a2d91ee359fd51b8\n",
      "  hostname: thunderball\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 4.244554132223129\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020175132027361542\n",
      "        policy_loss: -0.0333744018280413\n",
      "        total_loss: 0.4079398629255593\n",
      "        vf_explained_var: 0.8488204479217529\n",
      "        vf_loss: 0.43727923557162285\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.14\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.484148148148147\n",
      "    gpu_util_percent0: 0.3891703703703704\n",
      "    ram_util_percent: 82.02133333333333\n",
      "    vram_util_percent0: 0.5841084023018637\n",
      "  pid: 53290\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11424914909040942\n",
      "    mean_env_wait_ms: 74.34072931509414\n",
      "    mean_inference_ms: 6.956653517276726\n",
      "    mean_raw_obs_processing_ms: 60.0491084370592\n",
      "  time_since_restore: 2032.9076936244965\n",
      "  time_this_iter_s: 1009.1967341899872\n",
      "  time_total_s: 2032.9076936244965\n",
      "  timers:\n",
      "    learn_throughput: 8.701\n",
      "    learn_time_ms: 459743.51\n",
      "    sample_throughput: 7.191\n",
      "    sample_time_ms: 556213.216\n",
      "    update_time_ms: 13.073\n",
      "  timestamp: 1621601547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: 9c696_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/30.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/15.82 GiB heap, 0.0/5.42 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/afandang/exp/nb/PPO_2021-05-21_08-18-12<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_navsim_9c696_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2032.91</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">   -8.45</td><td style=\"text-align: right;\">               -6.41</td><td style=\"text-align: right;\">              -18.21</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/30.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/15.82 GiB heap, 0.0/5.42 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/afandang/exp/nb/PPO_2021-05-21_08-18-12<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_navsim_9c696_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2032.91</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">   -8.45</td><td style=\"text-align: right;\">               -6.41</td><td style=\"text-align: right;\">              -18.21</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 08:52:33,471\tINFO tune.py:450 -- Total run time: 2061.47 seconds (2055.61 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(pid=53288)\u001b[0m 2021-05-21 08:52:33 INFO [environment.py:407] Environment shut down with return code 0.\n"
     ]
    }
   ],
   "source": [
    "result = tune.run(\n",
    "    ppo.PPOTrainer,\n",
    "    config=config,\n",
    "    local_dir = '/home/afandang/exp/nb/',\n",
    "    stop={\"timesteps_total\": 4050}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f3744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T14:52:30.743967Z",
     "start_time": "2021-05-07T14:51:48.807195Z"
    }
   },
   "outputs": [],
   "source": [
    "result = tune.run(\n",
    "    ppo.PPOTrainer,\n",
    "    config=config,\n",
    "    local_dir = './ray_results/',\n",
    "    stop={\"episodes_total\": 50}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f5994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T16:52:22.226178Z",
     "start_time": "2021-05-14T16:51:56.521820Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = ppo.PPOTrainer(config, env=\"navsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f638562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:17:06.045676Z",
     "start_time": "2021-05-14T15:17:06.041741Z"
    }
   },
   "outputs": [],
   "source": [
    "print(agent.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c08228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T13:25:36.264213Z",
     "start_time": "2021-05-17T13:25:36.249482Z"
    }
   },
   "outputs": [],
   "source": [
    "del agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5ccf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:35:29.806182Z",
     "start_time": "2021-05-14T15:17:48.609545Z"
    }
   },
   "outputs": [],
   "source": [
    "result=agent.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b2ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T15:36:39.971224Z",
     "start_time": "2021-05-14T15:36:39.965753Z"
    }
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472437e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T18:22:38.235387Z",
     "start_time": "2021-05-14T16:52:22.270490Z"
    }
   },
   "outputs": [],
   "source": [
    "n_episodes = 5\n",
    "result = None\n",
    "for n in range(n_episodes):\n",
    "  result = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a92399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T12:57:13.353116Z",
     "start_time": "2021-04-30T12:57:13.347066Z"
    }
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72542aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_results = os.getenv(\"HOME\") + \"/ray_results/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6c262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T16:33:15.032557Z",
     "start_time": "2021-04-30T16:32:53.432975Z"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f27d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
